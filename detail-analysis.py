# pip install pandas numpy matplotlib seaborn scipy sqlitecloud python-dotenv scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr, shapiro
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv
import sqlitecloud
import os

# === ENVIRONMENT SETUP ===
load_dotenv()
CSV_PATH = os.getenv("FILE_NAME", "BÃ¼yÃ¼k_Veri_Deneyi.csv")
UPLOAD = int(os.getenv("UPLOAD", 0))
SAVE = int(os.getenv("SAVE", 1))
DB_ACCESS = os.getenv("DB_ACCESS")

if not DB_ACCESS:
    print("âš ï¸ Warning: No DB_ACCESS found. Cloud upload will be skipped.")

pd.set_option('display.float_format', lambda x: f'{x:.2f}')
pd.set_option('future.no_silent_downcasting', True)
sns.set_theme(style="darkgrid")

# === LOAD ===
print("ğŸ“Š Loading dataset...")
df = pd.read_csv(CSV_PATH, low_memory=False)
print(f"âœ… Loaded {len(df)} entries and {len(df.columns)} columns.\n")

# === CLEANING ===
print("ğŸ§¹ Cleaning data...")

df = df.drop(columns=[c for c in df.columns if "Onay" in c], errors="ignore")

df["Cinsiyet"] = df["Cinsiyet"].map({"ERKEK": 0, "KIZ": 1})
df["Okul TÃ¼rÃ¼"] = df["Okul TÃ¼rÃ¼"].map({"DEVLET": 0, "Ã–ZEL": 1})
df["SÄ±nÄ±f Seviyesi"] = df["SÄ±nÄ±f Seviyesi"].replace("HazÄ±rlÄ±k", 8.5).astype(float)

num_cols = [
    "YaÅŸ","Ortalama Uyku SÃ¼resi","Uykuya Dalmada Zorluk DÃ¼zeyi",
    "SabahlarÄ± Alarm Erteleme DÃ¼zeyi","Akademik BaÅŸarÄ± Memnuniyeti",
    "Uyku Kalitesi","Sabah Yorgun Uyanma DÃ¼zeyi","GÃ¼nlÃ¼k Ekran KullanÄ±m SÃ¼resi",
    "Son DÃ¶nem Not OrtalamasÄ±","LGS PuanÄ±","HaftalÄ±k Ders Ã‡alÄ±ÅŸma SÃ¼resi",
    "Derslerde Dikkat DaÄŸÄ±nÄ±klÄ±ÄŸÄ± DÃ¼zeyi","GÃ¼nlÃ¼k Kafein TÃ¼ketimi",
    "HaftalÄ±k Spor Yapma SÄ±klÄ±ÄŸÄ±","Genel Stres DÃ¼zeyi","Uyku Ã–ncesi Telefon KullanÄ±mÄ±"
]
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce")

def expand_multichoice(df, col, options):
    for opt in options:
        df[opt] = df[col].apply(lambda x: 1 if opt in str(x) else 0)
    return df.drop(columns=[col], errors="ignore")

if "SÄ±k KullandÄ±ÄŸÄ±nÄ±z Platformlar" in df.columns:
    df = expand_multichoice(df, "SÄ±k KullandÄ±ÄŸÄ±nÄ±z Platformlar", [
        "Instagram","TikTok","YouTube","Snapchat","Facebook",
        "X (Twitter)","Reddit","Discord","Pinterest","LinkedIn","Twitch"
    ])

if "Telefon, PC gibi teknolojik cihazlarÄ± genellikle hangi amaÃ§la kullanÄ±yorsunuz?" in df.columns:
    df = expand_multichoice(df, "Telefon, PC gibi teknolojik cihazlarÄ± genellikle hangi amaÃ§la kullanÄ±yorsunuz?", [
        "Sosyal Medya","Oyun","EÄŸitim","Video / Film Ä°zleme","Spor"
    ])

# Remove outliers (3-sigma)
for c in num_cols:
    if c in df.columns:
        df = df[np.abs(df[c] - df[c].mean()) <= (3 * df[c].std())]

# Normalize
scaler = StandardScaler()
num_df = df.select_dtypes(include=[np.number])
df[num_df.columns] = scaler.fit_transform(num_df)

df = df.map(lambda x: str(x).replace("\n", " ") if isinstance(x, str) else x)
print("âœ… Data cleaned and normalized.\n")

# === CORRELATION ===
corr = df.corr(numeric_only=True)
mask = np.triu(np.ones(corr.shape), k=1).astype(bool)
corr_pairs = corr.where(mask).unstack().dropna().sort_values(ascending=False)

plt.figure(figsize=(16,12))
sns.heatmap(corr, cmap="coolwarm", annot=False)
plt.title("Korelasyon HaritasÄ±")
plt.tight_layout()
plt.show(block=False)
plt.pause(0.001)

print("\nTop correlation pairs:")
print(corr_pairs.head(15))

# === SMART CORRELATION ===
def best_corr(x, y):
    if len(x) < 10 or len(y) < 10:
        return None, None
    try:
        if shapiro(x)[1] < 0.05 or shapiro(y)[1] < 0.05:
            return spearmanr(x, y)
        return pearsonr(x, y)
    except Exception:
        return None, None

print("\nğŸ“Š Significant correlations (p < 0.05):")
for (a, b) in corr_pairs.head(40).index:
    x, y = df[a].dropna(), df[b].dropna()
    r, p = best_corr(x, y)
    if r is not None and p < 0.05:
        print(f"{a} â†” {b}: r={r:.2f}, p={p:.4f}")

# === AUTO INSIGHTS ===
print("\nğŸ§  Auto Insights:")
for (a, b), r in corr_pairs.head(10).items():
    direction = "increases" if r > 0 else "decreases"
    strength = "strongly" if abs(r) > 0.6 else "moderately" if abs(r) > 0.3 else "weakly"
    print(f"As {a} increases, {b} {strength} {direction} (r={r:.2f})")

# === INTERACTIVE CORRELATION LOOP ===
while True:
    print("\nğŸ” Manual Correlation Checker")
    print("Type two column names to analyze, or press ENTER to exit.\n")
    print("Available columns:")
    print(", ".join(df.columns[:10]), "...")
    col1 = input("\nColumn 1: ").strip()
    if not col1:
        break
    col2 = input("Column 2: ").strip()
    if not col2:
        break
    if col1 not in df.columns or col2 not in df.columns:
        print("âš ï¸ Invalid column names, try again.")
        continue
    x, y = df[col1].dropna(), df[col2].dropna()
    r_p, p_p = pearsonr(x, y)
    r_s, p_s = spearmanr(x, y)
    print(f"\nPearson: r={r_p:.3f}, p={p_p:.5f}")
    print(f"Spearman: r={r_s:.3f}, p={p_s:.5f}")

    sns.lmplot(x=col1, y=col2, data=df, line_kws={'color': 'red'}, scatter_kws={'alpha':0.5})
    plt.title(f"{col1} vs {col2}\nPearson r={r_p:.2f}, Spearman r={r_s:.2f}")
    plt.show(block=False)
    plt.pause(0.001)

# === SAVE ===
if SAVE:
    df.to_csv("cleaned_data.csv", index=False)
    corr_pairs.to_csv("correlations.csv")
    print("\nğŸ’¾ Saved cleaned data and correlations locally.")

# === UPLOAD ===
if UPLOAD and DB_ACCESS:
    try:
        conn = sqlitecloud.connect(DB_ACCESS)
        cur = conn.cursor()
        cur.execute("DROP TABLE IF EXISTS bigdata_cleaned")
        cols = ", ".join([f'"{c}" TEXT' for c in df.columns])
        cur.execute(f"CREATE TABLE bigdata_cleaned ({cols});")
        sql = f"INSERT INTO bigdata_cleaned VALUES ({', '.join(['?' for _ in df.columns])});"
        cur.executemany(sql, df.astype(str).fillna("").values.tolist())
        conn.commit()
        conn.close()
        print("âœ… Uploaded successfully to SQLiteCloud.")
    except Exception as e:
        print("âš ï¸ Upload failed:", e)

# === SUMMARY ===
print("\n--- SUMMARY ---")
print(f"Entries: {len(df)}")
print(f"Columns: {len(df.columns)}")
print("Mean Sleep Quality:", df["Uyku Kalitesi"].mean().round(2) if "Uyku Kalitesi" in df else "N/A")
print("Mean Screen Time:", df["GÃ¼nlÃ¼k Ekran KullanÄ±m SÃ¼resi"].mean().round(2) if "GÃ¼nlÃ¼k Ekran KullanÄ±m SÃ¼resi" in df else "N/A")
print("Mean Academic Satisfaction:", df["Akademik BaÅŸarÄ± Memnuniyeti"].mean().round(2) if "Akademik BaÅŸarÄ± Memnuniyeti" in df else "N/A")

input("\nPress Enter to exit...")
