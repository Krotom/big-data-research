# pip install pandas numpy matplotlib seaborn scipy sqlitecloud python-dotenv

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
from dotenv import load_dotenv
import sqlitecloud
import os

# --- ENVIRONMENT SETUP ---
load_dotenv()
UPLOAD = int(os.getenv("UPLOAD"))
SAVE = int(os.getenv("SAVE"))
DB_ACCESS = os.getenv("DB_ACCESS")

if not DB_ACCESS:
    raise ValueError("âŒ Missing DB_ACCESS in .env file!")

pd.set_option('display.float_format', lambda x: f'{x:.2f}')
pd.set_option('future.no_silent_downcasting', True)
sns.set_theme(style="darkgrid")

# --- CONFIG ---
CSV_PATH = "BÃ¼yÃ¼k_Veri_Deneyi.csv"

# --- LOAD ---
print("ğŸ“Š Loading dataset...")
df = pd.read_csv(CSV_PATH, low_memory=False)
print(f"âœ… Loaded {len(df)} entries and {len(df.columns)} columns.\n")

# --- CLEAN ---
print("ğŸ§¹ Cleaning data...")

# Drop "Onay" columns
df = df.drop(columns=[col for col in df.columns if "Onay" in col], errors="ignore")

# Replace and convert known mappings
if "Cinsiyet" in df.columns:
    df["Cinsiyet"] = df["Cinsiyet"].map({"ERKEK": 0, "KIZ": 1})
if "Okul TÃ¼rÃ¼" in df.columns:
    df["Okul TÃ¼rÃ¼"] = df["Okul TÃ¼rÃ¼"].map({"DEVLET": 0, "Ã–ZEL": 1})
if "SÄ±nÄ±f Seviyesi" in df.columns:
    df["SÄ±nÄ±f Seviyesi"] = df["SÄ±nÄ±f Seviyesi"].replace("HazÄ±rlÄ±k", 8.5).astype(float)

# Numeric conversions
num_cols = [
    "YaÅŸ","Ortalama Uyku SÃ¼resi","Uykuya Dalmada Zorluk DÃ¼zeyi",
    "SabahlarÄ± Alarm Erteleme DÃ¼zeyi","Akademik BaÅŸarÄ± Memnuniyeti",
    "Uyku Kalitesi","Sabah Yorgun Uyanma DÃ¼zeyi","GÃ¼nlÃ¼k Ekran KullanÄ±m SÃ¼resi",
    "Son DÃ¶nem Not OrtalamasÄ±","LGS PuanÄ±","HaftalÄ±k Ders Ã‡alÄ±ÅŸma SÃ¼resi",
    "Derslerde Dikkat DaÄŸÄ±nÄ±klÄ±ÄŸÄ± DÃ¼zeyi","GÃ¼nlÃ¼k Kafein TÃ¼ketimi",
    "HaftalÄ±k Spor Yapma SÄ±klÄ±ÄŸÄ±","Genel Stres DÃ¼zeyi","Uyku Ã–ncesi Telefon KullanÄ±mÄ±"
]
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce")

# Expand multiple-choice columns
def expand_multichoice(df, col, options):
    for opt in options:
        df[opt] = df[col].apply(lambda x: 1 if opt in str(x) else 0)
    return df.drop(columns=[col], errors="ignore")

if "SÄ±k KullandÄ±ÄŸÄ±nÄ±z Platformlar" in df.columns:
    df = expand_multichoice(df, "SÄ±k KullandÄ±ÄŸÄ±nÄ±z Platformlar", [
        "Instagram","TikTok","YouTube","Snapchat","Facebook",
        "X (Twitter)","Reddit","Discord","Pinterest","LinkedIn","Twitch"
    ])
if "Telefon, PC gibi teknolojik cihazlarÄ± genellikle hangi amaÃ§la kullanÄ±yorsunuz?" in df.columns:
    df = expand_multichoice(df, "Telefon, PC gibi teknolojik cihazlarÄ± genellikle hangi amaÃ§la kullanÄ±yorsunuz?", [
        "Sosyal Medya","Oyun","EÄŸitim","Video / Film Ä°zleme","Spor"
    ])

print("âœ… Data cleaned successfully.\n")

# --- STATISTICS ---
print("ğŸ“ˆ Basic statistics:\n")
print(df.describe(include="all").transpose())
print("\nMissing values:\n", df.isna().sum())

# --- CORRELATION MATRIX ---
print("\nğŸ”— Computing correlations...")
corr = df.corr(numeric_only=True)
mask = np.triu(np.ones(corr.shape), k=1).astype(bool)
corr_pairs = corr.where(mask).unstack().dropna().sort_values(ascending=False)

plt.figure(figsize=(16,12))
sns.heatmap(corr, cmap="coolwarm", annot=False)
plt.title("Korelasyon HaritasÄ±")
plt.tight_layout()
plt.show(block=False)
plt.pause(0.001)

print("\nTop correlation pairs:")
print(corr_pairs.head(15))

# --- SIGNIFICANCE TESTS ---
print("\nğŸ“Š Statistically significant correlations (p < 0.05):")
for (a, b) in corr_pairs.head(30).index:
    x, y = df[a].dropna(), df[b].dropna()
    if len(x) > 5 and len(y) > 5:
        _, p = pearsonr(x, y)
        if p < 0.05:
            print(f"{a} â†” {b}: r={corr.loc[a,b]:.2f}, p={p:.4f}")

if UPLOAD:
    # --- UPLOAD CLEANED DATA ---
    print("\nâ˜ï¸ Uploading cleaned dataset to SQLiteCloud...")

    try:
        conn = sqlitecloud.connect(DB_ACCESS)
        cur = conn.cursor()

        # Drop the old table if exists
        cur.execute("DROP TABLE IF EXISTS bigdata_cleaned")

        # Create table with the same schema as the DataFrame
        cols = ", ".join([f'"{c}" TEXT' for c in df.columns])
        cur.execute(f"CREATE TABLE bigdata_cleaned ({cols});")

        # Insert all rows efficiently
        for _, row in df.iterrows():
            placeholders = ", ".join(["?" for _ in row])
            sql = f"INSERT INTO bigdata_cleaned VALUES ({placeholders});"
            cur.execute(sql, tuple(str(x) if pd.notna(x) else None for x in row))

        conn.commit()
        conn.close()
        print("âœ… Uploaded successfully to SQLiteCloud.")

    except Exception as e:
        print("âš ï¸ Upload failed:", e)

if SAVE:
    print("\nğŸ”— Saving cleaned data and correlations...")
    try:
        df.to_csv("cleaned_data.csv", index=False)
        corr_pairs.to_csv("correlations.csv")
        print("âœ… Saved successfully to local disk.")
    except Exception as e:
        print("âš ï¸ Saving failed:", e)

# --- SUMMARY ---
print("\n--- SUMMARY ---")
print(f"Entries: {len(df)}")
print(f"Columns: {len(df.columns)}")
print("Mean Sleep Quality:", df["Uyku Kalitesi"].mean().round(2))
print("Mean Screen Time:", df["GÃ¼nlÃ¼k Ekran KullanÄ±m SÃ¼resi"].mean().round(2))
print("Mean Academic Satisfaction:", df["Akademik BaÅŸarÄ± Memnuniyeti"].mean().round(2))

input("\nPress Enter to exit...")
